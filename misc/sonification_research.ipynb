{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# aimc_publications"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "aimc_2022/Aljanaki_2022__Attitude_towards_and_evaluation_of_computer-generated_music_in_music_listeners_and_musicians.pdf\n",
                        "aimc_2022/ChemlaRomeuSantos_2022__Challenges_in_creative_generative_models_for_music__a_divergence_maximization_perspective.pdf\n",
                        "aimc_2022/Chen_2022__Flat_Latent_Manifolds_for_Human-machine_Co-creation_of_Music.pdf\n",
                        "aimc_2022/Deruty_2022__Melatonin__A_Case_Study_on_AI-induced_Musical_Style.pdf\n",
                        "aimc_2022/Döbereiner_2022__Artistic_Potentials_of_Fallacies_in_AI_Research.pdf\n",
                        "aimc_2022/Dzwonczyk_2022__Source_Separation_Methods_for_Computer-assisted_Orchestration.pdf\n",
                        "aimc_2022/Gotham_2022__Beethoven_X__Es_könnte_sein.pdf\n",
                        "aimc_2022/Haki_2022__Real-Time_Drum_Accompaniment_Using_Transformer_Architecture.pdf\n",
                        "aimc_2022/Jan_2022__Universal_Acid_in_the_Computer_Chip__Music_Memetics_and_Metacreation.pdf\n",
                        "aimc_2022/Kobayashi_2022__MR4MR__Mixed_Reality_for_Melody_Reincarnation.pdf\n",
                        "aimc_2022/Lecompte-Bergeron_2022__Automatic_Transcription_of_Gambang_Balinese_Gamelan.pdf\n",
                        "aimc_2022/Lee_2022__Vivace__Web_Application_for_Real-Time_feedback_on_Piano_Performance.pdf\n",
                        "aimc_2022/Nguyen_2022__Random_Walks_on_Neo-Riemannian_Spaces__Towards_Generative_Transformations.pdf\n",
                        "aimc_2022/Ostermann_2022__Artificial_Music_Producer__Filtering_Music_Compositions_by_Artificial_Taste.pdf\n",
                        "aimc_2022/Shepardson_2022__Notochord__a_Flexible_Probabilistic_Model_for_Real-Time_MIDI_Performance.pdf\n",
                        "aimc_2022/Sturm_2022__The_Ai_Music_Generation_Challenge_2021__Summary_and_Results.pdf\n",
                        "aimc_2022/Tahiroğlu_2022__Augmented_Granular_Synthesis_Method_for_GAN_Latent_Space_with_Redundancy_Parameter.pdf\n",
                        "aimc_2022/TheSoundOfAICommunity_2022__From_Words_to_Sound__Neural_Audio_Synthesis_of_Guitar_Sounds_with_Timbral_Descriptors.pdf\n",
                        "aimc_2022/Uemura_2022__Morphing-Based_Reharmonization_with_VAE__Reducing_Dissonance_with_Consonance-Based_Loss_Function.pdf\n",
                        "aimc_2022/Waissbluth_2022_Synthesis_by_Layering__Learning_a_Variational_Space_of_Drum_Sounds.pdf\n",
                        "aimc_2022/Windswor_2022__Using_raw_audio_neural_network_systems_to_define_musical_creativity.pdf\n",
                        "aimc_2023/\"A Synth made of Chicken Nuggets you Play with your Elbows- A workshop exploring AI supported Musical Instrument Design.pdf\n",
                        "aimc_2023/Agential Instruments Design Workshop.pdf\n",
                        "aimc_2023/Are words enough?.pdf\n",
                        "aimc_2023/Bela-IREE- An Approach to Embedded Machine Learning for Real-Time Music Interaction.pdf\n",
                        "aimc_2023/Caring Trouble and Musical AI- Considerations towards a Feminist Musical AI.pdf\n",
                        "aimc_2023/Deep Learning with Audio- An Explorative Syllabus for Music Composition and Production.pdf\n",
                        "aimc_2023/Deploying NN-Based Generative Models of Symbolic Music as VST3 Plugins using NeuralMidiFx Wrapper.pdf\n",
                        "aimc_2023/Embodied Perspectives on Musical AI (EmAI) Workshop.pdf\n",
                        "aimc_2023/Exploring Latent Spaces of Tonal Music using Variational Autoencoders.pdf\n",
                        "aimc_2023/Extensible Embodied Knowledge- Bridging Performance Practice and Intelligent Performance System Design.pdf\n",
                        "aimc_2023/Fourth Annual Machine Folk Music School.pdf\n",
                        "aimc_2023/Human-AI Musicking- A Framework for Designing AI for Music Co-creativity.pdf\n",
                        "aimc_2023/Liveness and machine listening in musical live coding- A conceptual framework for designing agent-based systems.pdf\n",
                        "aimc_2023/Music AI's Potential Impact- Scoping the terms of the debate about value.pdf\n",
                        "aimc_2023/Musical and Meta-Musical Conversations.pdf\n",
                        "aimc_2023/NeuralMidiFx- A Wrapper Template for Deploying Neural Networks as VST3 Plugins.pdf\n",
                        "aimc_2023/Parsing Musical Structureto Enable Meaningful Variations.pdf\n",
                        "aimc_2023/Revisiting Reynolds - Autonomous Agents for Spatial Audiovisual Composition and Performances.pdf\n",
                        "aimc_2023/Risks and Opportunities from Artificial Creativity.pdf\n",
                        "aimc_2023/Sequential Pitch Distributions for Raga Detection.pdf\n",
                        "aimc_2023/Silicon for Orchestra and Artificial Intelligence.pdf\n",
                        "aimc_2023/Statistical evaluation of abc-formatted music at the levels of items and corpora.pdf\n",
                        "aimc_2023/The A in AIMC.pdf\n",
                        "aimc_2023/The Ai Music Generation Challenge 2022- Summary and Results.pdf\n",
                        "aimc_2023/The Phenomenology of Deconstructivist Aesthetics in Music- An Autoethnography of Errors, Erasures, Permutations, Discontinuities, Paradoxes and Artificial Intelligences.pdf\n",
                        "aimc_2023/Virtual AI Jam- AI-Driven Virtual Musicians for Human-in-the-Loop Musical Improvisation.pdf\n",
                        "aimc_2023/YouTube Mirror- An Interactive Audiovisual Installation based on Cross-Modal Generative Modeling.pdf\n",
                        "aimc_2023/[neuralnet]- A Pure Data External for the Creation of Neural Networks Written in Pure C.pdf\n",
                        "aimc_2024/>> genesis - v2 <<.pdf\n",
                        "aimc_2024/A Deep Learning Framework for Musical Acoustics Simulations.pdf\n",
                        "aimc_2024/A listening agent for live control of synthesis parameters using reinforcement learning.pdf\n",
                        "aimc_2024/AI Music Studies- Preparing for the Coming Flood.pdf\n",
                        "aimc_2024/Agonistic Dialogue on the Value and Impact of AI Music Applications.pdf\n",
                        "aimc_2024/Augmenting the Expressivity of the Notochord Generative MIDI Model for Arca's \"The Light Comes in the Name of the Voice\" Magnetic Resonator Piano Installation.pdf\n",
                        "aimc_2024/Bias II.pdf\n",
                        "aimc_2024/Breathless.pdf\n",
                        "aimc_2024/Ciung Wanara; Interactive Gestural Audiovisual Composition (2023).pdf\n",
                        "aimc_2024/Computer-Assisted Composition- Survey and hands-on with Calliope.pdf\n",
                        "aimc_2024/Cuticles.pdf\n",
                        "aimc_2024/DISEnsemble live performance.pdf\n",
                        "aimc_2024/Daim™- AIAI ^^.pdf\n",
                        "aimc_2024/Deep Drawing- An Intermedia AI Co-Performer.pdf\n",
                        "aimc_2024/Deep Steps- A Generative AI Step Sequencer.pdf\n",
                        "aimc_2024/Designing an AI-creativity music course.pdf\n",
                        "aimc_2024/Endless Generative AI- A Practical Tutorial.pdf\n",
                        "aimc_2024/Experience replay.pdf\n",
                        "aimc_2024/Exploring Semiotic Interactions in Text-to-Audio- A Demonstration of Udio's Text- to-Audio Capabilities.pdf\n",
                        "aimc_2024/Flexible Melody Harmonization with Rhythmic Complexity based on Cognitive Music Theory.pdf\n",
                        "aimc_2024/Generating Mixcode Popular Songs with Artificial Intelligence- Concepts, Plans, and Speculations.pdf\n",
                        "aimc_2024/Ghost in the Piano – An Investigation into AI, Robotics and Musical Performance.pdf\n",
                        "aimc_2024/GoGo Musebots.pdf\n",
                        "aimc_2024/Grammatical Structure and Grammatical Variations in Non-Metric Iranian Classical Music-Updated.pdf\n",
                        "aimc_2024/Hand-on workshop on PRiSM's Music Gesture Recognition tool.pdf\n",
                        "aimc_2024/Investigating the Human-Machine Relationship in Sampling-Based AI Music- Material-Centric Approach to Liveness.pdf\n",
                        "aimc_2024/Jazz Guitar Voice-Leading Chord Fingerings With Long Short-Term Memory.pdf\n",
                        "aimc_2024/Large Audio AI Models for Fixed-Media Electronics in \"Prelude- To Listening\".pdf\n",
                        "aimc_2024/Learning to Learn- A Reflexive Case Study of PRiSM SampleRNN.pdf\n",
                        "aimc_2024/Mosaïque - Concatenative Synthesis Instrument for the Practicing Musicians.pdf\n",
                        "aimc_2024/Navigating Challenges in Multimodal Music Data Management for AI Systems.pdf\n",
                        "aimc_2024/Off-the-shelf- Improvising with a Minimal Intelligent Musical Instrument in Mixed Reality.pdf\n",
                        "aimc_2024/Phrase-Level Symbolic Music Generation.pdf\n",
                        "aimc_2024/Prestidigitation.pdf\n",
                        "aimc_2024/Reviving Traditional Raga Music- An AI-Driven Approach for Melody Generation Using GPT-4.pdf\n",
                        "aimc_2024/Schistosité II (2023), for 4-ch electronic sounds.pdf\n",
                        "aimc_2024/Semantic and Semiotic Interplays in Text-to-Audio AI- Exploring Cognitive Dynamics and Musical Interactions.pdf\n",
                        "aimc_2024/Sentiment Analysis of AI Generated Music Using Latent Dirichlet Allocation (LDA).pdf\n",
                        "aimc_2024/Solaris- Jazz-AI Quartet Performance.pdf\n",
                        "aimc_2024/Sounding out extra-normal AI voice- Non-normative musical engagements with normative AI voice and speech technologies.pdf\n",
                        "aimc_2024/Sparks of Musical AGI? Challenges and perspectives in music co-creation with LLMs.pdf\n",
                        "aimc_2024/Spomenik I.pdf\n",
                        "aimc_2024/Stochastic Pirate Radio (KSPR)- Generative AI applied to simulate commercial radio.pdf\n",
                        "aimc_2024/Strategies for building AI-enhanced audio software with impact.pdf\n",
                        "aimc_2024/Stravinsky three Pieces with Live Animation.pdf\n",
                        "aimc_2024/Streamlines.pdf\n",
                        "aimc_2024/TAM reveals AI negativity bias in VR music performances.pdf\n",
                        "aimc_2024/The Artist in A.I. Art.pdf\n",
                        "aimc_2024/The corpus’ body. Embodied Interaction from Machine-Learning in Human-Machine Improvisation..pdf\n",
                        "aimc_2024/Three is a crowd?.pdf\n",
                        "aimc_2024/Tidal MerzA- Combining affective modelling and autonomous code generation through Reinforcement Learning.pdf\n",
                        "aimc_2024/Transsonic - Sonic Lightning.pdf\n",
                        "aimc_2024/Unformation.pdf\n",
                        "aimc_2024/WhaleBeat Karaoke.pdf\n",
                        "aimc_2024/break me, ai.pdf\n",
                        "aimc_2024/der Küchenchef performance at club night.pdf\n",
                        "aimc_2024/glemöhnic.pdf\n",
                        "aimc_2024/saccades.pdf\n"
                    ]
                }
            ],
            "source": [
                "import dol \n",
                "\n",
                "s = dol.Files('/Users/thorwhalen/Dropbox/_odata/ai_contexts/projects/sonification/aimc_publications')\n",
                "print(*sorted(s), sep='\\n')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "51474"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "from hubcap import RepoReader, create_markdown_from_discussion_jdict\n",
                "import pathlib\n",
                "\n",
                "r = RepoReader('https://github.com/infinvest/mood/')\n",
                "md = create_markdown_from_discussion_jdict(r['discussions'][5])\n",
                "target = '/Users/thorwhalen/Dropbox/_odata/ai_contexts/projects/sonification/mood_modeling.md'\n",
                "pathlib.Path(target).write_text(md)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Selection of AIMC papers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pdfdol import concat_pdfs\n",
                "\n",
                "concat_pdfs(\n",
                "    '/Users/thorwhalen/Dropbox/_odata/ai_contexts/projects/sonification/by_year/aimc_publications/aimc_2024',\n",
                "    save_filepath=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "src = '/Users/thorwhalen/Dropbox/_odata/ai_contexts/projects/sonification/aimc_publications/by_year'\n",
                "targ = '/Users/thorwhalen/Dropbox/_odata/ai_contexts/projects/sonification/aimc_publications/selection'\n",
                "\n",
                "aimc_selected_papers = {\n",
                "    \"aimc_2022/TheSoundOfAICommunity_2022__From_Words_to_Sound__Neural_Audio_Synthesis_of_Guitar_Sounds_with_Timbral_Descriptors.pdf\": \n",
                "    \"Directly relevant as it addresses transforming 'words to sound' using neural audio synthesis. Provides insights into mapping semantic information to audio features, crucial for sonifying political discourse.\",\n",
                "\n",
                "    \"aimc_2024/Semantic and Semiotic Interplays in Text-to-Audio AI- Exploring Cognitive Dynamics and Musical Interactions.pdf\": \n",
                "    \"Highly relevant; focuses on semantic and semiotic aspects of text-to-audio generation, exploring how meaning and context translate to audio, which is central to representing the nuances of political discourse.\",\n",
                "\n",
                "    \"aimc_2024/Exploring Semiotic Interactions in Text-to-Audio- A Demonstration of Udio's Text- to-Audio Capabilities.pdf\": \n",
                "    \"Highly relevant; demonstrates text-to-audio using Udio, a state-of-the-art tool, focusing on the interplay of semiotics in the text-to-audio generation, crucial for conveying the subtleties of political discourse.\",\n",
                "\n",
                "    \"aimc_2022/Deruty_2022__Melatonin__A_Case_Study_on_AI-induced_Musical_Style.pdf\": \n",
                "    \"Relevant; explores AI-induced musical style, offering insights into representing emotional/semantic attributes (like mood vectors) in musical terms, applicable to conveying the mood of political discourse.\",\n",
                "\n",
                "    \"aimc_2024/A listening agent for live control of synthesis parameters using reinforcement learning.pdf\": \n",
                "    \"Relevant; discusses dynamically adjusting sound parameters based on input, which relates to using mood vectors to drive sonification, suggesting techniques for responsive and nuanced audio representation.\",\n",
                "\n",
                "    \"aimc_2022/ChemlaRomeuSantos_2022__Challenges_in_creative_generative_models_for_music__a_divergence_maximization_perspective.pdf\": \n",
                "    \"Somewhat relevant; addresses challenges in AI-driven audio generation, providing background on the capabilities and limitations of models used in sonification, particularly for creative and expressive purposes.\",\n",
                "\n",
                "    \"aimc_2023/Are words enough?.pdf\": \n",
                "    \"Somewhat relevant; explores the limitations of language in conveying meaning, conceptually supporting the use of sonification as an alternative representation for complex semantic information in political discourse.\",\n",
                "\n",
                "    \"aimc_2022/Windswor_2022__Using_raw_audio_neural_network_systems_to_define_musical_creativity.pdf\": \n",
                "    \"Somewhat relevant; discusses using neural networks to process audio, a technical aspect of your project, though focused on musical creativity rather than direct text-to-sound mapping for discourse analysis.\"\n",
                "}\n",
                "\n",
                "import dol \n",
                "import os\n",
                "\n",
                "selected_store = dol.filt_iter(dol.Files(src), filt=aimc_selected_papers.keys())\n",
                "target_store = dol.Files(targ)\n",
                "\n",
                "for k, v in selected_store.items():\n",
                "    kk = os.path.basename(k)\n",
                "    target_store[kk] = v"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import contaix \n",
                "import pathlib \n",
                "\n",
                "files_to_transform_to_md = [\n",
                "    '/Users/thorwhalen/Dropbox/_odata/ai_contexts/projects/sonification/aimc_publications/selection/Are words enough?.pdf',\n",
                "    \"/Users/thorwhalen/Dropbox/_odata/ai_contexts/projects/sonification/aimc_publications/selection/A listening agent for live control of synthesis parameters using reinforcement learning.pdf\",\n",
                "]\n",
                "for f in files_to_transform_to_md:\n",
                "    b = pathlib.Path(f).read_bytes()\n",
                "    md = contaix.bytes_to_markdown(b, input_format='.pdf')\n",
                "    pathlib.Path(f).with_suffix('.md').write_text(md)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Introduce \"Sonifying Semantics,\" (directed by Thor Whalen), which explores the use of AI to transform political discourse into sound. \n",
                "* text-to-audio AI's role in translating political discourse (Semantic/Semiotic Interplays & Interactions).   \n",
                "* mapping emotion/mood to audio (Neural Audio Synthesis, Melatonin).   \n",
                "* dynamic sound parameter control via AI (listening agent).   \n",
                "Briefly touch on AI audio generation challenges and sonification's potential for representing semantic information."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Getting urls and their contents from markdown file"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "len(urls_with_context)=174\n"
                    ]
                }
            ],
            "source": [
                "md_file = '/Users/thorwhalen/Dropbox/_odata/ai_contexts/misc/sonification_research.md'\n",
                "md_string = open(md_file).read()\n",
                "\n",
                "from contaix import extract_urls\n",
                "\n",
                "urls_with_context = list(extract_urls(md_string))\n",
                "print(f\"{len(urls_with_context)=}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[(' Sonification Research Prompts for Python Toolkit Development',\n",
                            "  'https://github.com/thorwhalen/sonification/discussions/4#discussioncomment-12614294'),\n",
                            " ('Conceptual Map of Sonification',\n",
                            "  'https://github.com/thorwhalen/sonification/discussions/4#discussioncomment-12614565'),\n",
                            " ('Articles etc. (Finding What to Read)',\n",
                            "  'https://github.com/thorwhalen/sonification/discussions/4#discussioncomment-12616646'),\n",
                            " ('Techniques, Datasets, and Tools',\n",
                            "  'https://github.com/thorwhalen/sonification/discussions/4#discussioncomment-12625392'),\n",
                            " ('see openreview', 'https://openreview.net/forum?id=B1x1ma4tDr'),\n",
                            " ('see this article',\n",
                            "  'https://vbn.aau.dk/files/466610617/SMC_2021_paper_58.pdf'),\n",
                            " ('Neural Audio Synthesis', 'https://arxiv.org/abs/2001.00001'),\n",
                            " ('Deep Learning for Audio Synthesis', 'https://arxiv.org/abs/2002.00002'),\n",
                            " ('Web Audio API', 'https://webaudio.github.io/web-audio-api/'),\n",
                            " ('Sonification Handbook', 'http://sonification.de/handbook/')]"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "urls_with_context[:10]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Unique contexts: len(unique_contexts)=110\n"
                    ]
                }
            ],
            "source": [
                "contexts = list(dict(urls_with_context).keys())\n",
                "unique_contexts = set(contexts)\n",
                "print(f'Unique contexts: {len(unique_contexts)=}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "len(url_counts)=62\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "[('https://arxiv.org/abs/2209.04465', 8),\n",
                            " ('https://www.earthdata.nasa.gov/blog/from-data-melody-data-sonification-its-role-open-science',\n",
                            "  8),\n",
                            " ('https://www.researchgate.net/publication/354982892_AIive_Interactive_Visualization_and_Sonification_of_Neural_Networks_in_Virtual_Reality',\n",
                            "  4),\n",
                            " ('https://www.sciencedirect.com/science/article/pii/S2589004221008415', 4),\n",
                            " ('https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7078008/', 4),\n",
                            " ('https://onlinelibrary.wiley.com/doi/10.1111/cgf.15114', 4),\n",
                            " ('https://www.researchgate.net/publication/337943521_A_sonification_model_for_real-time_anomaly_detection_in_machine_learning_supported_cybersecurity',\n",
                            "  4),\n",
                            " ('https://www.sciencedirect.com/science/article/pii/S2352396419300337', 4),\n",
                            " ('https://www.researchgate.net/publication/363094564_Sonification_as_a_Tool_for_Data_Analysis_Usability_and_Compliance_Evaluation_Study',\n",
                            "  4),\n",
                            " ('https://www.icad.org/', 4),\n",
                            " ('https://www.mcs.anl.gov/~kaper/Sonification/index.html', 4),\n",
                            " ('https://www.researchgate.net/publication/228577110_The_discipline_of_interactive_sonification',\n",
                            "  4),\n",
                            " ('https://www.researchgate.net/publication/213799070_Theory_of_Sonification',\n",
                            "  4),\n",
                            " ('https://www.perkins.org/resource/sonification-summary-page/', 4),\n",
                            " ('https://handbook.floeproject.org/sonification', 4),\n",
                            " ('https://www.researchgate.net/publication/291821907_Sonification_and_Music_Music_and_Sonification',\n",
                            "  4),\n",
                            " ('https://www.mdpi.com/journal/algorithms/special_issues/MU_MS', 4),\n",
                            " ('https://www.academia.edu/78589380/HCI_Design_and_Interactive_Sonification_for_Fingers_and_Ears',\n",
                            "  4),\n",
                            " ('https://link.springer.com/chapter/10.1007/978-3-540-70816-2_18', 4),\n",
                            " ('https://www.academia.edu/68785319/The_Importance_of_Interaction_in_Sonification',\n",
                            "  4)]"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from collections import Counter \n",
                "\n",
                "url_counts = Counter([x[1] for x in urls_with_context]).most_common()\n",
                "print(f\"{len(url_counts)=}\")\n",
                "url_counts[:20]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "len(unique_urls)=62\n"
                    ]
                }
            ],
            "source": [
                "unique_urls = dict(url_counts).keys()\n",
                "print(f\"{len(unique_urls)=}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Download url content"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'https/example.com_f/file.pdf'"
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from graze import url_to_localpath\n",
                "url_to_localpath('https://example.com/file.pdf')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(36, 25, 62)"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from graze import Graze \n",
                "\n",
                "g = Graze('/Users/thorwhalen/Dropbox/_odata/ai_contexts/sonification_files')\n",
                "\n",
                "failed = dict()\n",
                "for url in unique_urls:\n",
                "    try:\n",
                "        g[url]\n",
                "    except Exception as e:\n",
                "        failed[url] = e\n",
                "        #print(f\"Failed to download {url}: {e}\")\n",
                "len(g), len(failed), len(unique_urls)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['https://webaudio.github.io/web-audio-api',\n",
                            " 'https://www.unoosa.org/documents/pdf/Space4PersonswithDisabilites/UNOOSA_Special_Report_on_Sonification_2023.pdf',\n",
                            " 'https://www.loudnumbers.net',\n",
                            " 'https://github.com/thorwhalen/sonification/discussions/4#discussioncomment-12614565',\n",
                            " 'https://github.com/thorwhalen/sonification/discussions/4#discussioncomment-12625392',\n",
                            " 'https://github.com/thorwhalen/sonification/discussions/4#discussioncomment-12614294',\n",
                            " 'https://github.com/thorwhalen/sonification/discussions/4#discussioncomment-12616646',\n",
                            " 'https://www.academia.edu/68785319/The_Importance_of_Interaction_in_Sonification',\n",
                            " 'https://www.academia.edu/78589380/HCI_Design_and_Interactive_Sonification_for_Fingers_and_Ears',\n",
                            " 'https://www.academia.edu/Documents/in/Data_Sonification',\n",
                            " 'https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-021-04362-7',\n",
                            " 'https://programminghistorian.org/en/lessons/sonification',\n",
                            " 'https://www.mcs.anl.gov/~kaper/Sonification/index.html',\n",
                            " 'https://opensonifications.net/open-sonifications-DIS.pdf',\n",
                            " 'https://sonification.design',\n",
                            " 'https://arxiv.org/abs/2209.04465',\n",
                            " 'https://arxiv.org/abs/2208.02494',\n",
                            " 'https://arxiv.org/abs/2108.09537',\n",
                            " 'https://arxiv.org/abs/2002.00002',\n",
                            " 'https://arxiv.org/abs/2402.00156',\n",
                            " 'https://arxiv.org/abs/2001.00001',\n",
                            " 'https://arxiv.org/abs/2404.00016',\n",
                            " 'https://arxiv.org/abs/2412.09152',\n",
                            " 'https://openreview.net/forum?id=B1x1ma4tDr',\n",
                            " 'https://www.mdpi.com/journal/algorithms/special_issues/MU_MS',\n",
                            " 'https://vbn.aau.dk/files/466610617/SMC_2021_paper_58.pdf',\n",
                            " 'https://doi.org/10.3389/fdata.2023.1206081',\n",
                            " 'https://doi.org/10.3389/fcomm.2020.00046',\n",
                            " 'https://doi.org/10.3389/fpsyg.2022.1020102',\n",
                            " 'https://doi.org/10.3389/fcomm.2024.1288896',\n",
                            " 'https://doi.org/10.3390/s24010065',\n",
                            " 'https://hdl.handle.net/1853/49960',\n",
                            " 'https://hdl.handle.net/1853/66336',\n",
                            " 'https://www.icad.org',\n",
                            " 'https://link.springer.com/chapter/10.1007/978-3-540-70816-2_18',\n",
                            " 'http://www.fon.hum.uva.nl/praat']"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "list(g)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Getting url contents into readable files (pdf, text, markdown)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "/Users/thorwhalen/Dropbox/py/proj/i/pdfdol/pdfdol/tools.py\n",
                        "/Users/thorwhalen/Dropbox/py/proj/t/aix/aix/contexts.py\n"
                    ]
                }
            ],
            "source": [
                "import pdfdol.tools\n",
                "import contaix \n",
                "\n",
                "print(pdfdol.tools.__file__)\n",
                "print(contaix.__file__)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Contexts for sonification"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import contaix \n",
                "\n",
                "_ = contaix.code_aggregate(\n",
                "    'tonal', \n",
                "    egress='/Users/thorwhalen/Dropbox/_odata/ai_contexts/py_packages_code/mine/tonal.py.md'\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "306824"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import dol\n",
                "import pathlib\n",
                "\n",
                "\n",
                "rootdir = '/Users/thorwhalen/Dropbox/_odata/ai_contexts/projects/sonification/sonification_packages_docs_and_code'\n",
                "s = dol.cache_iter(dol.TextFiles(rootdir), keys_cache=sorted)\n",
                "\n",
                "aggregate = dol.store_aggregate(s, kv_to_item=lambda k, v: f\"# {k}\\n\\n{v.strip()}\\n\\n\")\n",
                "\n",
                "# save t to a file of parent_dir\n",
                "(pathlib.Path(rootdir).parent / 'sonification_packages_docs_and_code.md').write_text(aggregate)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "2317396"
                        ]
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from contaix import bytes_store_to_markdown_store, aggregate_store\n",
                "from graze import Graze\n",
                "import pathlib\n",
                "\n",
                "grazed_sonification = Graze('/Users/thorwhalen/Dropbox/_odata/ai_contexts/projects/sonification/sonification_files')\n",
                "md_sonification = bytes_store_to_markdown_store(grazed_sonification)\n",
                "aggregate_md = aggregate_store(md_sonification, min_number_of_duplicated_lines=10) \n",
                "pathlib.Path('/Users/thorwhalen/Dropbox/_odata/ai_contexts/projects/sonification/sonification_files.md').write_text(aggregate_md)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "9656267"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from contaix import markdown_of_site\n",
                "import pathlib\n",
                "md = markdown_of_site('https://belangeo.github.io/pyo/', depth=3)\n",
                "targ = '/Users/thorwhalen/Dropbox/_odata/ai_contexts/projects/sonification/sonification_packages_docs_and_code/pyo_docs.md'\n",
                "pathlib.Path(targ).write_text(md)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pdfdol import get_pdf\n",
                "\n",
                "pdf_bytes = get_pdf(md)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "6975938"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "targ = '/Users/thorwhalen/Dropbox/_odata/ai_contexts/projects/sonification/sonification_packages_docs_and_code/pyo_docs.pdf'\n",
                "pathlib.Path(targ).write_bytes(pdf_bytes)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Scrap: Getting urls (framework WIP)\n",
                "\n",
                "Intended for an extension of `contaix`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Seed code\n",
                "\n",
                "from typing import MutableMapping, Mapping, Union\n",
                "from dol import Files \n",
                "import requests\n",
                "from graze import url_to_localpath, url_to_contents\n",
                "\n",
                "def ensure_store(store):\n",
                "    if isinstance(store, str):\n",
                "        store = Files(store)\n",
                "    return store\n",
                "\n",
                "def store_urls_contents(\n",
                "        urls, \n",
                "        *,\n",
                "        url_to_key=url_to_localpath, \n",
                "        url_to_contents=lambda url: requests.get(url).content,\n",
                "        save_store: Union[MutableMapping, str] = '~/Downloads', \n",
                "        verbose: int = 1\n",
                "    ):\n",
                "    save_store = ensure_store(save_store)\n",
                "    # if urls is a dict, then it is a mapping from urls to the keys they should be stored in\n",
                "    # if not, the when should make it so with url_to_key\n",
                "    if not isinstance(urls, Mapping):\n",
                "        urls = {url: url_to_key(url) for url in urls}\n",
                "    for url, key in urls.items():\n",
                "        if verbose:\n",
                "            print(f\"Downloading {url} to {key}\")\n",
                "        save_store[key] = url_to_contents(url)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import re\n",
                "import requests\n",
                "from typing import Callable, Iterator, List, Dict, Tuple, Optional, Union, Pattern, Mapping, MutableMapping\n",
                "from dol import Files\n",
                "from graze import url_to_localpath, url_to_contents\n",
                "from functools import partial\n",
                "from io import BytesIO\n",
                "\n",
                "\n",
                "def extract_urls(\n",
                "    markdown: str,\n",
                "    pattern: Optional[Pattern] = None,\n",
                "    extractor: Optional[Callable[[re.Match], Tuple[str, str]]] = None\n",
                ") -> Iterator[Tuple[str, str]]:\n",
                "    \"\"\"\n",
                "    Extract URLs and their context from a markdown string.\n",
                "    \n",
                "    Args:\n",
                "        markdown: The markdown string to process\n",
                "        pattern: A compiled regex pattern to match URLs and their context\n",
                "                 Defaults to matching markdown hyperlinks [context](url)\n",
                "        extractor: A function that extracts (context, url) from a match\n",
                "                  Defaults to extracting from markdown hyperlinks\n",
                "                  \n",
                "    Returns:\n",
                "        Iterator of (context, url) pairs\n",
                "        \n",
                "    >>> text = \"[Google](https://google.com) and [GitHub](https://github.com)\"\n",
                "    >>> list(extract_urls(text))\n",
                "    [('Google', 'https://google.com'), ('GitHub', 'https://github.com')]\n",
                "    \"\"\"\n",
                "    if pattern is None:\n",
                "        # Default pattern matches markdown hyperlinks: [context](url)\n",
                "        pattern = re.compile(r'\\[([^\\]]+)\\]\\(([^)]+)\\)')\n",
                "    \n",
                "    if extractor is None:\n",
                "        # Default extractor for markdown hyperlinks\n",
                "        def extractor(match: re.Match) -> Tuple[str, str]:\n",
                "            return match.group(1), match.group(2)\n",
                "    \n",
                "    for match in pattern.finditer(markdown):\n",
                "        yield extractor(match)\n",
                "\n",
                "\n",
                "def ensure_store(store):\n",
                "    \"\"\"\n",
                "    Ensure the store is a MutableMapping, converting string paths to Files objects.\n",
                "    \n",
                "    Args:\n",
                "        store: A MutableMapping or a string path\n",
                "        \n",
                "    Returns:\n",
                "        A MutableMapping instance\n",
                "    \"\"\"\n",
                "    if isinstance(store, str):\n",
                "        if store.startswith('~'):\n",
                "            store = os.path.expanduser(store)\n",
                "        os.makedirs(store, exist_ok=True)\n",
                "        store = Files(store)\n",
                "    return store\n",
                "\n",
                "\n",
                "def sanitize_filename(title: str) -> str:\n",
                "    \"\"\"\n",
                "    Sanitize a title to create a valid filename.\n",
                "    \n",
                "    Args:\n",
                "        title: The title to sanitize\n",
                "        \n",
                "    Returns:\n",
                "        A sanitized filename\n",
                "    \"\"\"\n",
                "    return re.sub(r\"[^\\w\\-_\\. ]\", \"_\", title)\n",
                "\n",
                "\n",
                "def store_urls_contents(\n",
                "    urls, \n",
                "    *,\n",
                "    url_to_key=url_to_localpath, \n",
                "    url_to_contents=lambda url: requests.get(url).content,\n",
                "    save_store: Union[MutableMapping, str] = '~/Downloads', \n",
                "    verbose: int = 1\n",
                "):\n",
                "    \"\"\"\n",
                "    Download contents from URLs and store them in a mapping.\n",
                "    \n",
                "    Args:\n",
                "        urls: A mapping of URLs to keys, or an iterable of URLs\n",
                "        url_to_key: Function to convert a URL to a key\n",
                "        url_to_contents: Function to get contents from a URL\n",
                "        save_store: A MutableMapping or path where contents will be stored\n",
                "        verbose: Level of verbosity (0=quiet, 1=normal, 2=verbose)\n",
                "    \"\"\"\n",
                "    save_store = ensure_store(save_store)\n",
                "    # if urls is a dict, then it is a mapping from urls to the keys they should be stored in\n",
                "    # if not, then we should make it so with url_to_key\n",
                "    if not isinstance(urls, Mapping):\n",
                "        urls = {url: url_to_key(url) for url in urls}\n",
                "    for url, key in urls.items():\n",
                "        if verbose:\n",
                "            print(f\"Downloading {url} to {key}\")\n",
                "        save_store[key] = url_to_contents(url)\n",
                "\n",
                "\n",
                "def is_pdf_content(content) -> bool:\n",
                "    \"\"\"\n",
                "    Check if content is a PDF by looking at its header.\n",
                "    \n",
                "    Args:\n",
                "        content: The content to check\n",
                "        \n",
                "    Returns:\n",
                "        True if the content appears to be a PDF\n",
                "    \"\"\"\n",
                "    if isinstance(content, bytes) and len(content) >= 4:\n",
                "        return content.startswith(b\"%PDF\")\n",
                "    return False\n",
                "\n",
                "\n",
                "def extract_article_urls(\n",
                "    markdown_string: str,\n",
                "    pattern: Optional[Pattern] = None\n",
                ") -> Iterator[Tuple[str, str]]:\n",
                "    \"\"\"\n",
                "    Extract article titles and URLs from a markdown string.\n",
                "    \n",
                "    Args:\n",
                "        markdown_string: The markdown string containing titles and URLs\n",
                "        pattern: A compiled regex pattern to match URLs and their context\n",
                "                Default pattern matches markdown style links\n",
                "                \n",
                "    Returns:\n",
                "        Iterator of (title, url) pairs\n",
                "    \"\"\"\n",
                "    if pattern is None:\n",
                "        # This matches the most common markdown link patterns including the one in the original code\n",
                "        pattern = re.compile(r'\\*?\\*?\\[([^\\]]+)\\]\\(([^)]+)\\)\\*?\\*?')\n",
                "    \n",
                "    return extract_urls(markdown_string, pattern)\n",
                "\n",
                "\n",
                "def download_articles(\n",
                "    md_string: str,\n",
                "    save_dir: str = os.path.expanduser(\"~/Downloads\"),\n",
                "    *,\n",
                "    save_non_pdf: bool = False,\n",
                "    verbose: bool = True,\n",
                "    extract_urls_func: Callable = extract_article_urls\n",
                ") -> List[str]:\n",
                "    \"\"\"\n",
                "    Downloads articles from the given markdown string and saves them as PDF files.\n",
                "\n",
                "    Args:\n",
                "        md_string: The markdown-style string containing titles and URLs\n",
                "        save_dir: The root directory to save the downloaded PDFs. Defaults to '~/Downloads'\n",
                "        save_non_pdf: Whether to save non-PDF content. Defaults to False\n",
                "        verbose: Whether to print detailed messages. Defaults to True\n",
                "        extract_urls_func: Function to extract (title, url) pairs from markdown\n",
                "\n",
                "    Returns:\n",
                "        A list of URLs that failed to download or were invalid PDFs\n",
                "\n",
                "    Example:\n",
                "    >>> md_string = '''\n",
                "    ... - **[Valid PDF](https://example.com/file.pdf)**: A valid PDF file.\n",
                "    ... - **[Invalid PDF](https://example.com/file.html)**: An HTML page, not a PDF.\n",
                "    ... '''  # doctest: +SKIP\n",
                "    >>> download_articles(md_string, save_non_pdf=True)  # doctest: +SKIP\n",
                "    Downloaded: Valid PDF -> ~/Downloads/Valid_PDF.pdf\n",
                "    Skipped (HTML or non-PDF): Invalid PDF from https://example.com/file.html\n",
                "    Non-PDF content saved to: ~/Downloads/Invalid_PDF_non_pdf.html\n",
                "    ['https://example.com/file.html']\n",
                "    \"\"\"\n",
                "    # Ensure save_dir exists\n",
                "    save_dir = os.path.expanduser(save_dir)\n",
                "    os.makedirs(save_dir, exist_ok=True)\n",
                "    \n",
                "    def clog(msg):\n",
                "        if verbose:\n",
                "            print(msg)\n",
                "    \n",
                "    store = Files(save_dir)\n",
                "    failed_urls = []\n",
                "    \n",
                "    for title, url in extract_urls_func(md_string):\n",
                "        sanitized_title = sanitize_filename(title)\n",
                "        filename = f\"{sanitized_title}.pdf\"\n",
                "        \n",
                "        try:\n",
                "            # Use the store_urls_contents framework but modify it to handle PDFs specially\n",
                "            response = requests.get(url, stream=True)\n",
                "            response.raise_for_status()\n",
                "            \n",
                "            # Check Content-Type header\n",
                "            content_type = response.headers.get(\"Content-Type\", \"\")\n",
                "            if \"application/pdf\" not in content_type:\n",
                "                clog(f\"Skipped (HTML or non-PDF): {title} from {url} (Content-Type: {content_type})\")\n",
                "                \n",
                "                if save_non_pdf:\n",
                "                    # Save non-PDF content with appropriate extension\n",
                "                    ext = \"html\" if \"text/html\" in content_type else \"data\"\n",
                "                    non_pdf_path = os.path.join(save_dir, f\"{sanitized_title}_non_pdf.{ext}\")\n",
                "                    with open(non_pdf_path, \"wb\") as f:\n",
                "                        for chunk in response.iter_content(chunk_size=8192):\n",
                "                            f.write(chunk)\n",
                "                    clog(f\"Non-PDF content saved to: {non_pdf_path}\")\n",
                "                \n",
                "                failed_urls.append(url)\n",
                "                continue\n",
                "            \n",
                "            # Get the content and verify it's actually a PDF\n",
                "            first_chunk = next(response.iter_content(chunk_size=8192))\n",
                "            if not first_chunk.startswith(b\"%PDF\"):\n",
                "                clog(f\"Invalid PDF content: {title} from {url}\")\n",
                "                \n",
                "                if save_non_pdf:\n",
                "                    invalid_pdf_path = os.path.join(save_dir, f\"{sanitized_title}_invalid.pdf\")\n",
                "                    with open(invalid_pdf_path, \"wb\") as f:\n",
                "                        f.write(first_chunk)\n",
                "                        for chunk in response.iter_content(chunk_size=8192):\n",
                "                            f.write(chunk)\n",
                "                    clog(f\"Invalid PDF content saved to: {invalid_pdf_path}\")\n",
                "                \n",
                "                failed_urls.append(url)\n",
                "                continue\n",
                "            \n",
                "            # Save the PDF file\n",
                "            filepath = os.path.join(save_dir, filename)\n",
                "            with open(filepath, \"wb\") as f:\n",
                "                f.write(first_chunk)\n",
                "                for chunk in response.iter_content(chunk_size=8192):\n",
                "                    f.write(chunk)\n",
                "            \n",
                "            clog(f\"Downloaded: {title} -> {filepath}\")\n",
                "        \n",
                "        except Exception as e:\n",
                "            clog(f\"Failed to download {title} from {url}: {e}\")\n",
                "            failed_urls.append(url)\n",
                "    \n",
                "    return failed_urls\n",
                "\n",
                "\n",
                "def download_articles_by_section(\n",
                "    md_string: str, \n",
                "    rootdir: Optional[str] = None, \n",
                "    save_non_pdf: bool = False, \n",
                "    *, \n",
                "    section_marker: str = r\"###\",\n",
                "    extract_urls_func: Callable = extract_article_urls\n",
                ") -> Dict[str, List[str]]:\n",
                "    \"\"\"\n",
                "    Downloads articles from a markdown string organized by sections into subdirectories.\n",
                "\n",
                "    Args:\n",
                "        md_string: The markdown string with sections and articles\n",
                "        rootdir: The root directory where subdirectories for sections will be created\n",
                "                Defaults to '~/Downloads'\n",
                "        save_non_pdf: Whether to save non-PDF content. Defaults to False\n",
                "        section_marker: The markdown heading marker that denotes a section. Defaults to '###'\n",
                "        extract_urls_func: Function to extract (title, url) pairs from markdown\n",
                "\n",
                "    Returns:\n",
                "        A dictionary with section names as keys and lists of failed URLs as values\n",
                "    \"\"\"\n",
                "    if rootdir is None:\n",
                "        rootdir = os.path.expanduser(\"~/Downloads\")\n",
                "    else:\n",
                "        rootdir = os.path.expanduser(rootdir)\n",
                "    \n",
                "    # Ensure the root directory exists\n",
                "    os.makedirs(rootdir, exist_ok=True)\n",
                "    \n",
                "    # Parse sections and their content\n",
                "    section_pattern = section_marker + r\" (.*?)\\n(.*?)(?=\\n\" + section_marker + \"|\\Z)\"\n",
                "    sections = re.findall(section_pattern, md_string, re.DOTALL)\n",
                "    \n",
                "    failed_urls_by_section = {}\n",
                "    \n",
                "    for section_title, section_content in sections:\n",
                "        # Create a snake-case directory name for the section\n",
                "        sanitized_section_title = re.sub(r\"[^\\w\\s]\", \"\", section_title).strip().replace(\" \", \"_\").lower()\n",
                "        section_dir = os.path.join(rootdir, sanitized_section_title)\n",
                "        os.makedirs(section_dir, exist_ok=True)\n",
                "        \n",
                "        print(f\"\\nProcessing section: {section_title} (Directory: {section_dir})\")\n",
                "        \n",
                "        # Download articles for this section\n",
                "        failed_urls = download_articles(\n",
                "            section_content, \n",
                "            save_dir=section_dir, \n",
                "            save_non_pdf=save_non_pdf,\n",
                "            extract_urls_func=extract_urls_func\n",
                "        )\n",
                "        failed_urls_by_section[section_title] = failed_urls\n",
                "    \n",
                "    return failed_urls_by_section\n",
                "\n",
                "\n",
                "def download_with_store_framework(\n",
                "    md_string: str,\n",
                "    save_dir: str = os.path.expanduser(\"~/Downloads\"),\n",
                "    *,\n",
                "    save_non_pdf: bool = False,\n",
                "    verbose: bool = True,\n",
                "    extract_urls_func: Callable = extract_article_urls\n",
                ") -> List[str]:\n",
                "    \"\"\"\n",
                "    Alternative implementation using the store_urls_contents framework.\n",
                "    \n",
                "    This shows how to use the store_urls_contents framework for article downloading,\n",
                "    but note that it handles PDF checking differently from the original implementation.\n",
                "    \n",
                "    Args:\n",
                "        md_string: The markdown-style string containing titles and URLs\n",
                "        save_dir: The root directory to save the downloaded files\n",
                "        save_non_pdf: Whether to save non-PDF content\n",
                "        verbose: Whether to print detailed messages\n",
                "        extract_urls_func: Function to extract URLs from markdown\n",
                "        \n",
                "    Returns:\n",
                "        A list of URLs that failed to download or were invalid PDFs\n",
                "    \"\"\"\n",
                "    # Ensure save_dir exists\n",
                "    save_dir = os.path.expanduser(save_dir)\n",
                "    os.makedirs(save_dir, exist_ok=True)\n",
                "    \n",
                "    # Create a custom url_to_key function that maintains title information\n",
                "    def url_to_key_with_title(url_title_pair):\n",
                "        url, title = url_title_pair\n",
                "        sanitized_title = sanitize_filename(title)\n",
                "        return f\"{sanitized_title}.pdf\"\n",
                "    \n",
                "    # Custom url_to_contents function that validates PDFs\n",
                "    def get_pdf_content(url_title_pair):\n",
                "        url, title = url_title_pair\n",
                "        response = requests.get(url, stream=True)\n",
                "        response.raise_for_status()\n",
                "        \n",
                "        content_type = response.headers.get(\"Content-Type\", \"\")\n",
                "        if \"application/pdf\" not in content_type:\n",
                "            if verbose:\n",
                "                print(f\"Skipped (HTML or non-PDF): {title} from {url}\")\n",
                "            if not save_non_pdf:\n",
                "                raise ValueError(f\"Not a PDF: {url}\")\n",
                "                \n",
                "        # Read the content\n",
                "        content = BytesIO()\n",
                "        for chunk in response.iter_content(chunk_size=8192):\n",
                "            content.write(chunk)\n",
                "        \n",
                "        content_bytes = content.getvalue()\n",
                "        \n",
                "        # Check if it's a valid PDF\n",
                "        if not content_bytes.startswith(b\"%PDF\"):\n",
                "            if verbose:\n",
                "                print(f\"Invalid PDF content: {title} from {url}\")\n",
                "            if not save_non_pdf:\n",
                "                raise ValueError(f\"Invalid PDF content: {url}\")\n",
                "        \n",
                "        return content_bytes\n",
                "    \n",
                "    # Extract URLs from markdown\n",
                "    url_title_pairs = [(url, title) for title, url in extract_urls_func(md_string)]\n",
                "    \n",
                "    # Create a mapping from URL-title pairs to keys\n",
                "    url_title_to_key = {pair: url_to_key_with_title(pair) for pair in url_title_pairs}\n",
                "    \n",
                "    # Download and store the content\n",
                "    failed_urls = []\n",
                "    for pair in url_title_pairs:\n",
                "        url, title = pair\n",
                "        try:\n",
                "            if verbose:\n",
                "                print(f\"Downloading: {title} from {url}\")\n",
                "            \n",
                "            key = url_title_to_key[pair]\n",
                "            content = get_pdf_content(pair)\n",
                "            \n",
                "            # Save to file\n",
                "            with open(os.path.join(save_dir, key), 'wb') as f:\n",
                "                f.write(content)\n",
                "                \n",
                "            if verbose:\n",
                "                print(f\"Downloaded: {title} -> {os.path.join(save_dir, key)}\")\n",
                "                \n",
                "        except Exception as e:\n",
                "            if verbose:\n",
                "                print(f\"Failed to download {title} from {url}: {e}\")\n",
                "            failed_urls.append(url)\n",
                "    \n",
                "    return failed_urls"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "p10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
